{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import pandas as pd\n",
    "from skimage.transform import rotate, resize\n",
    "from skimage.util import pad\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame.from_csv(\"data_set.csv\")\n",
    "\n",
    "#load files to memory\n",
    "img_files_paths = set(df[\"left\"].values)\n",
    "img_files = {}\n",
    "for img_file_path in img_files_paths:\n",
    "    img = io.imread(img_file_path)\n",
    "    img_files[img_file_path] = img\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data set size = 380\n",
      "sample 0/380\n",
      "data set size after augmentation = 780\n"
     ]
    }
   ],
   "source": [
    "#augment data_set by rotating positive examples\n",
    "def normalize_shape(img):\n",
    "    max_shape = (300,300)\n",
    "    normalized = []\n",
    "    if img.shape[0] < max_shape[0] and img.shape[1] < max_shape[1]:\n",
    "        h, w = img.shape\n",
    "        p_up = int((max_shape[0] - h)/2) +1\n",
    "        p_left = int((max_shape[1] - w)/2) + 1\n",
    "        normalized = pad(img, ((p_up,p_up),(p_left,p_left)), 'constant', constant_values=(0, 0))[0:max_shape[0],0:max_shape[1]]\n",
    "    else:\n",
    "        normalized = resize(img, max_shape, mode = 'constant')\n",
    "    if normalized.shape != max_shape:\n",
    "        print(normalized.shape)\n",
    "    return normalized\n",
    "\n",
    "\n",
    "print(\"data set size = {}\".format(len(df)))\n",
    "to_append = []\n",
    "for idx, row in df.iterrows():\n",
    "    if idx % 1000 == 0:\n",
    "        print(\"sample {}/{}\".format(idx, len(df)))\n",
    "    df.set_value(idx, \"left\", normalize_shape(img_files[row[\"left\"]]))\n",
    "    df.set_value(idx, \"right\", normalize_shape(img_files[row[\"right\"]]))\n",
    "    if row[\"y\"] == 1:\n",
    "        for i in range(0,20):\n",
    "            angle = random.randrange(360)\n",
    "            rotated = rotate(img_files[row[\"right\"]], angle, resize=True)\n",
    "            rotated = normalize_shape(rotated)\n",
    "            to_append.append({\"left\": normalize_shape(img_files[row[\"left\"]]), \"right\":rotated, \"y\":1})\n",
    "            \n",
    "df = df.append(to_append, ignore_index=True)\n",
    "print(\"data set size after augmentation = {}\".format(len(df)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 300)\n",
      "(300, 300)\n"
     ]
    }
   ],
   "source": [
    "max_shape = max(map(lambda x: x.shape, df[\"right\"].values))\n",
    "print(max_shape)\n",
    "#for key, value in img_files.items():\n",
    " #   img_files[key] = resize(value, max_shape)\n",
    "\n",
    "min_shape = min(map(lambda x: x.shape, df[\"right\"].values))\n",
    "print(min_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(780, 2, 300, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\echomil\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:47: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_39 (InputLayer)           (None, 300, 300, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_40 (InputLayer)           (None, 300, 300, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 296, 296, 32) 832         input_39[0][0]                   \n",
      "                                                                 input_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 148, 148, 32) 0           conv2d_22[0][0]                  \n",
      "                                                                 conv2d_22[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 144, 144, 32) 25632       max_pooling2d_5[0][0]            \n",
      "                                                                 max_pooling2d_5[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 72, 72, 32)   0           conv2d_23[0][0]                  \n",
      "                                                                 conv2d_23[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 72, 72, 64)   2112        max_pooling2d_6[0][0]            \n",
      "                                                                 max_pooling2d_6[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 331776)       0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 331776)       0           dense_13[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "merge_12 (Merge)                (None, 1)            0           flatten_13[0][0]                 \n",
      "                                                                 flatten_14[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 28,576\n",
      "Trainable params: 28,576\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 624 samples, validate on 156 samples\n",
      "Epoch 1/10\n",
      " 32/624 [>.............................] - ETA: 5:45 - loss: 0.5000 - acc: 0.5000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-135-dad7434704d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m \u001b[0mtrained_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_train_left\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train_right\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_val_left\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val_right\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_validation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\echomil\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1629\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1630\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1631\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1633\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Users\\echomil\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\echomil\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2332\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2333\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\echomil\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\echomil\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 965\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\echomil\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1015\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Users\\echomil\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\echomil\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Dropout, Conv2D, Merge, Flatten, MaxPooling2D\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "INPUT_SHAPE = (300,300,1)\n",
    "\n",
    "def exponent_neg_manhattan_distance(left, right):\n",
    "    return K.exp(-K.sum(K.abs(left-right), axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "X = np.array(list(zip(df[\"left\"].values,df[\"right\"].values)))\n",
    "Y = df[\"y\"].values\n",
    "print(X.shape)\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "x_l_input = Input(shape=INPUT_SHAPE)\n",
    "x_r_input = Input(shape=INPUT_SHAPE)\n",
    "\n",
    "conv_layer_1 = Conv2D(32, activation=\"relu\", kernel_size = (5,5))\n",
    "x_l = conv_layer_1(x_l_input)\n",
    "x_r = conv_layer_1(x_r_input)\n",
    "\n",
    "pool_1 = MaxPooling2D()\n",
    "x_l = pool_1(x_l)\n",
    "x_r = pool_1(x_r)\n",
    "\n",
    "conv_layer_2 = Conv2D(32, activation=\"relu\", kernel_size = (5,5))\n",
    "x_l = conv_layer_2(x_l)\n",
    "x_r = conv_layer_2(x_r)\n",
    "\n",
    "pool_2 = MaxPooling2D()\n",
    "x_l = pool_2(x_l)\n",
    "x_r = pool_2(x_r)\n",
    "\n",
    "dense_layer = Dense(64, activation=\"relu\", kernel_initializer='normal')\n",
    "x_l = dense_layer(x_l)\n",
    "x_r = dense_layer(x_r)\n",
    "\n",
    "x_l = Flatten()(x_l)\n",
    "x_r = Flatten()(x_r)\n",
    "\n",
    "malstm_distance = Merge(\n",
    "    mode=lambda x: exponent_neg_manhattan_distance(x[0], x[1]),\n",
    "    output_shape=lambda x: (x[0][0], 1))([x_l, x_r])\n",
    "\n",
    "model = Model(inputs=[x_l_input,x_r_input], outputs=malstm_distance)\n",
    "model.compile(optimizer=\"adadelta\",\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "X_train_left = np.array(list(map(lambda x: x.reshape(INPUT_SHAPE), X_train[:,0])))\n",
    "X_train_right = np.array(list(map(lambda x: x.reshape(INPUT_SHAPE), X_train[:,1])))\n",
    "X_val_right = np.array(list(map(lambda x: x.reshape(INPUT_SHAPE), X_validation[:,1])))\n",
    "X_val_left = np.array(list(map(lambda x: x.reshape(INPUT_SHAPE), X_validation[:,0])))\n",
    "\n",
    "\n",
    "trained_model = model.fit([X_train_left,X_train_right ], Y_train, batch_size=8, epochs = 10, validation_data = ([X_val_left, X_val_right], Y_validation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
